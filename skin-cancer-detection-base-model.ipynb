{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2275763,"sourceType":"datasetVersion","datasetId":1370616},{"sourceId":10377603,"sourceType":"datasetVersion","datasetId":6428263}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wandb","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom PIL import Image\nimport os\nimport torch.nn.functional as F\nimport wandb\nfrom torchsummary import summary","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Застосування:\nМедичні зображення: Bicubic добре підходить для задач, де важливі дрібні деталі, наприклад, аналіз родимок, рентгенівських знімків, МРТ тощо.\nГрафіка та фотографія: Використовується для масштабування фотографій, щоб уникнути пікселізації.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass Encoder(nn.Module):\n    def __init__(self, in_channels=3, out_channels=16, latent_dim=200):\n        super().__init__()\n        self.out_channels = out_channels\n\n        self.net = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),  # (600, 450)\n            nn.ReLU(),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),  \n            nn.ReLU(),\n            nn.Conv2d(out_channels, 2 * out_channels, kernel_size=3, stride=2, padding=1),  # (300, 225)\n            nn.ReLU(),\n            nn.Conv2d(2 * out_channels, 2 * out_channels, kernel_size=3, padding=1),  \n            nn.ReLU(),\n            nn.Conv2d(2 * out_channels, 4 * out_channels, kernel_size=3, stride=2, padding=1),  # (150, 113)\n            nn.ReLU(),\n            nn.Conv2d(4 * out_channels, 4 * out_channels, kernel_size=3, padding=1),  \n            nn.ReLU(),\n        )\n        \n        # Розраховуємо розмір після згорткових шарів: (4 * out_channels, 150, 113)\n        self.flatten_size = 4 * out_channels * 150 * 113\n\n        self.fc = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(self.flatten_size, latent_dim),\n            nn.ReLU(),\n        )\n\n    def forward(self, x):\n        x = x.view(-1, 3, 600, 450)\n        x = self.net(x)\n        x = self.fc(x)\n        return x\n\n\nclass Decoder(nn.Module):\n    def __init__(self, in_channels=3, out_channels=16, latent_dim=200):\n        super().__init__()\n        self.out_channels = out_channels\n\n        self.fc = nn.Sequential(\n            nn.Linear(latent_dim, 4 * out_channels * 150 * 113),\n            nn.ReLU(),\n        )\n\n        self.conv = nn.Sequential(\n            nn.ConvTranspose2d(4 * out_channels, 4 * out_channels, kernel_size=3, padding=1),  # (150, 113)\n            nn.ReLU(),\n            nn.ConvTranspose2d(4 * out_channels, 2 * out_channels, kernel_size=3, stride=2, padding=1, output_padding=0),  # (300, 225)\n            nn.ReLU(),\n            nn.ConvTranspose2d(2 * out_channels, 2 * out_channels, kernel_size=3, padding=1),  \n            nn.ReLU(),\n            nn.ConvTranspose2d(2 * out_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=0),  # (600, 450)\n            nn.ReLU(),\n            nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(out_channels, in_channels, kernel_size=3, padding=1),  \n            nn.Sigmoid(),  # Для нормалізації виходу до [0, 1]\n        )\n\n    def forward(self, x):\n        x = self.fc(x)\n        x = x.view(-1, 4 * self.out_channels, 150, 113)  # Відновлюємо форму для згорткових шарів\n        x = self.conv(x)\n        return x\n\n\nclass Autoencoder(nn.Module):\n    def __init__(self, encoder, decoder):\n        super().__init__()\n        self.encoder = encoder\n        # self.encoder.to(device)\n        self.decoder = decoder\n        # self.decoder.to(device)\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Функція для обчислення коефіцієнта кореляції\ndef correlation_coefficient(x, y):\n    x_mean = np.mean(x)\n    y_mean = np.mean(y)\n    \n    numerator = np.sum((x - x_mean) * (y - y_mean))\n    denominator = np.sqrt(np.sum((x - x_mean)**2) * np.sum((y - y_mean)**2))\n    \n    return numerator / denominator\n\n# Функція для обчислення порогу\ndef calculate_threshold(correlation_coeffs):\n    mu_c = np.mean(correlation_coeffs)\n    sigma_c = np.std(correlation_coeffs)\n    threshold = mu_c - 0.5 * sigma_c\n    return threshold","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wandb login 492953ddcda0576b6e6ebf89860aed0ccd177efe","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"run_name = f\"Autoencoder all examples\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.init(\n    # set the wandb project where this run will be logged\n    project=\"Skin cancer BASE model\",\n\n    # track hyperparameters and run metadata\n    config={\n    \"epochs\" : 10,\n    \"batch_size\" : 16,\n    \"learning_rate\" : 0.001,\n    },\n    name=run_name\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Клас для завантаження зображень з папки\nclass CustomDataset(Dataset):\n    def __init__(self, folder_path, transform=None, max_images=None):\n        self.image_paths = [os.path.join(folder_path, fname) for fname in os.listdir(folder_path) if fname.endswith('.jpg') or fname.endswith('.png')]\n        if max_images is not None:\n            self.image_paths = self.image_paths[:max_images]  # Обмежуємо кількість зображень до max_images\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_name = self.image_paths[idx]\n        image = Image.open(img_name).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_autoencoder(model, dataloader, criterion, optimizer, scheduler, device, epochs):\n    \"\"\"\n    Функція для тренування автоенкодера.\n    \n    Args:\n        model: Модель автоенкодера.\n        dataloader: Завантажувач даних.\n        criterion: Функція втрат.\n        optimizer: Оптимізатор.\n        scheduler: Планувальник швидкості навчання.\n        device: Пристрій (CPU або GPU).\n        epochs: Кількість епох.\n\n    Returns:\n        Модель після тренування.\n    \"\"\"\n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0.0\n        \n        for data in dataloader:\n            data = data.to(device)\n            \n            optimizer.zero_grad()\n            output = model(data)\n            \n            # Враховуємо розмір для уникнення помилки розміру\n            data_resized = F.interpolate(data, size=(600, 450), mode='bicubic', align_corners=False)\n            \n            loss = criterion(output, data_resized)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n\n        # Середнє значення втрат для епохи\n        average_loss = train_loss / len(dataloader)\n        \n        # Виведення результатів\n        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {average_loss}\")\n        \n        # Логування втрат у wandb\n        wandb.log({\"epoch\": epoch + 1, \"loss\": average_loss})\n        \n        # Оновлення швидкості навчання\n        scheduler.step(average_loss)\n\n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoder = Encoder(in_channels=3, out_channels=16, latent_dim=1000)\ndecoder = Decoder(in_channels=3, out_channels=16, latent_dim=1000)\nautoencoder_model = Autoencoder(encoder, decoder)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"summary(autoencoder_model, (3, 600, 450))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"summary(decoder, (200, )) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(encoder)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Підготовка даних\nimage_folder = \"/kaggle/input/ham1000-segmentation-and-classification/images\"  # Шлях до папки з зображеннями\ntransform = transforms.Compose([\n    transforms.Resize((600, 450), interpolation=transforms.InterpolationMode.BICUBIC),\n    transforms.ToTensor()\n    # Якщо не потрібно нормалізувати, можете прибрати:\n    # transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)) \n])\n\ndataset = CustomDataset(image_folder, transform)\ndataloader = DataLoader(dataset, batch_size=wandb.config.batch_size, shuffle=True)\n\n# # Створення та тренування автоенкодера\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nautoencoder = autoencoder.to(device)\noptimizer = optim.Adam(autoencoder.parameters(), lr=wandb.config.learning_rate)\ncriterion = nn.MSELoss()  # Використовуємо BCE для бінарної класифікації\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=4, factor=0.1)\n\n# Виклик функції тренування\nautoencoder = train_autoencoder(\n    model=autoencoder,\n    dataloader=dataloader,\n    criterion=criterion,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    device=device,\n    epochs=wandb.config.epochs\n)\n\n# Збереження моделі\ntorch.save(autoencoder.state_dict(), \"cnn_autoencoder.pth\")\nwandb.save(\"cnn_autoencoder.pth\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Отримання вихідного зображення після реконструкції\ntest_image = Image.open(\"/kaggle/input/dddddsd/photo_5_2025-01-05_14-16-42.jpg\").convert('RGB')\ntest_image = transform(test_image).unsqueeze(0).to(device)\noutput_image = autoencoder(test_image).detach().cpu().numpy()\n\n# Обчислення коефіцієнту кореляції\ntest_image_resized = transforms.functional.resize(test_image, size=(600, 456), interpolation=transforms.InterpolationMode.BICUBIC)\ninput_pixels = test_image_resized.squeeze(0).cpu().numpy().flatten()\n\nreconstructed_pixels = output_image.flatten()\ncorr_value = correlation_coefficient(input_pixels, reconstructed_pixels)\nprint(f\"Correlation Coefficient: {corr_value}\")\n\n# Масив кореляцій для класу (приклад)\ncorrelation_coeffs = np.random.rand(100)  # Масив кореляцій для класу\n\n# Обчислення порогу для цього класу\nthreshold = calculate_threshold(correlation_coeffs)\nprint(f\"Threshold: {threshold}\")\n\n# Перевірка чи зображення належить тому ж класу\nif corr_value > threshold:\n    print(\"Зображення належить тому ж класу.\")\nelse:\n    print(\"Зображення не належить тому ж класу.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}