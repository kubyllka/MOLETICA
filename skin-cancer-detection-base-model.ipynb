{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":10377603,"datasetId":6428263,"databundleVersionId":10690479},{"sourceType":"datasetVersion","sourceId":2275763,"datasetId":1370616,"databundleVersionId":2316863}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T13:46:32.921233Z","iopub.execute_input":"2025-01-05T13:46:32.921474Z","iopub.status.idle":"2025-01-05T13:46:42.198049Z","shell.execute_reply.started":"2025-01-05T13:46:32.921447Z","shell.execute_reply":"2025-01-05T13:46:42.197221Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.18.7)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.19.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.10/site-packages (from wandb) (4.12.2)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np # linear algebra\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom PIL import Image\nimport os\nimport torch.nn.functional as F\nimport wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T13:48:05.972319Z","iopub.execute_input":"2025-01-05T13:48:05.972741Z","iopub.status.idle":"2025-01-05T13:48:12.752075Z","shell.execute_reply.started":"2025-01-05T13:48:05.972686Z","shell.execute_reply":"2025-01-05T13:48:12.751154Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"Застосування:\nМедичні зображення: Bicubic добре підходить для задач, де важливі дрібні деталі, наприклад, аналіз родимок, рентгенівських знімків, МРТ тощо.\nГрафіка та фотографія: Використовується для масштабування фотографій, щоб уникнути пікселізації.","metadata":{}},{"cell_type":"code","source":"class CNN_Autoencoder(nn.Module):\n    def __init__(self):\n        super(CNN_Autoencoder, self).__init__()\n        \n        # Encoder\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),  # Output: (batch_size, 32, 300, 225)\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # Output: (batch_size, 64, 150, 113)\n            nn.ReLU(),\n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # Output: (batch_size, 128, 75, 56)\n            nn.ReLU(),\n        )\n        \n        # Decoder\n        self.decoder = nn.Sequential(\n            # The first transpose convolution will output (batch_size, 64, 150, 113)\n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  \n            nn.ReLU(),\n            # The second transpose convolution will output (batch_size, 32, 300, 226)\n            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=0),  \n            nn.ReLU(),\n            # The final transpose convolution will output (batch_size, 3, 600, 450)\n            nn.ConvTranspose2d(32, 3, kernel_size=3, stride=2, padding=1, output_padding=0),  \n            nn.Sigmoid()  # For normalization within [0, 1]\n        )\n        \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T13:48:15.961290Z","iopub.execute_input":"2025-01-05T13:48:15.962055Z","iopub.status.idle":"2025-01-05T13:48:15.971612Z","shell.execute_reply.started":"2025-01-05T13:48:15.962013Z","shell.execute_reply":"2025-01-05T13:48:15.970167Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Функція для обчислення коефіцієнта кореляції\ndef correlation_coefficient(x, y):\n    x_mean = np.mean(x)\n    y_mean = np.mean(y)\n    \n    numerator = np.sum((x - x_mean) * (y - y_mean))\n    denominator = np.sqrt(np.sum((x - x_mean)**2) * np.sum((y - y_mean)**2))\n    \n    return numerator / denominator\n\n# Функція для обчислення порогу\ndef calculate_threshold(correlation_coeffs):\n    mu_c = np.mean(correlation_coeffs)\n    sigma_c = np.std(correlation_coeffs)\n    threshold = mu_c - 0.5 * sigma_c\n    return threshold","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T13:48:18.816373Z","iopub.execute_input":"2025-01-05T13:48:18.817406Z","iopub.status.idle":"2025-01-05T13:48:18.823596Z","shell.execute_reply.started":"2025-01-05T13:48:18.817365Z","shell.execute_reply":"2025-01-05T13:48:18.822263Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!wandb login 492953ddcda0576b6e6ebf89860aed0ccd177efe","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T13:48:20.685268Z","iopub.execute_input":"2025-01-05T13:48:20.686134Z","iopub.status.idle":"2025-01-05T13:48:24.265983Z","shell.execute_reply.started":"2025-01-05T13:48:20.686093Z","shell.execute_reply":"2025-01-05T13:48:24.264638Z"}},"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"run_name = f\"Autoencoder 1000 examples\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T13:48:24.268950Z","iopub.execute_input":"2025-01-05T13:48:24.269501Z","iopub.status.idle":"2025-01-05T13:48:24.275305Z","shell.execute_reply.started":"2025-01-05T13:48:24.269442Z","shell.execute_reply":"2025-01-05T13:48:24.274045Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"wandb.init(\n    # set the wandb project where this run will be logged\n    project=\"Skin cancer BASE model\",\n\n    # track hyperparameters and run metadata\n    config={\n    \"epochs\" : 40,\n    \"batch_size\" : 16,\n    \"learning_rate\" : 0.001,\n    },\n    name=run_name\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T13:48:24.276730Z","iopub.execute_input":"2025-01-05T13:48:24.277203Z","iopub.status.idle":"2025-01-05T13:48:27.476822Z","shell.execute_reply.started":"2025-01-05T13:48:24.277168Z","shell.execute_reply":"2025-01-05T13:48:27.475616Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkkaterynabilyk\u001b[0m (\u001b[33mkkaterynabilyk-lviv-polytechnic-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250105_134825-vj37w4dj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/kkaterynabilyk-lviv-polytechnic-national-university/Skin%20cancer%20BASE%20model/runs/vj37w4dj' target=\"_blank\">Autoencoder 1000 examples</a></strong> to <a href='https://wandb.ai/kkaterynabilyk-lviv-polytechnic-national-university/Skin%20cancer%20BASE%20model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/kkaterynabilyk-lviv-polytechnic-national-university/Skin%20cancer%20BASE%20model' target=\"_blank\">https://wandb.ai/kkaterynabilyk-lviv-polytechnic-national-university/Skin%20cancer%20BASE%20model</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/kkaterynabilyk-lviv-polytechnic-national-university/Skin%20cancer%20BASE%20model/runs/vj37w4dj' target=\"_blank\">https://wandb.ai/kkaterynabilyk-lviv-polytechnic-national-university/Skin%20cancer%20BASE%20model/runs/vj37w4dj</a>"},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/kkaterynabilyk-lviv-polytechnic-national-university/Skin%20cancer%20BASE%20model/runs/vj37w4dj?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7a35b1dca410>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Клас для завантаження зображень з папки\nclass CustomDataset(Dataset):\n    def __init__(self, folder_path, transform=None, max_images=None):\n        self.image_paths = [os.path.join(folder_path, fname) for fname in os.listdir(folder_path) if fname.endswith('.jpg') or fname.endswith('.png')]\n        if max_images is not None:\n            self.image_paths = self.image_paths[:max_images]  # Обмежуємо кількість зображень до max_images\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_name = self.image_paths[idx]\n        image = Image.open(img_name).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T13:48:27.478984Z","iopub.execute_input":"2025-01-05T13:48:27.479355Z","iopub.status.idle":"2025-01-05T13:48:27.488318Z","shell.execute_reply.started":"2025-01-05T13:48:27.479319Z","shell.execute_reply":"2025-01-05T13:48:27.487232Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Підготовка даних\nimage_folder = \"/kaggle/input/ham1000-segmentation-and-classification/images\"  # Шлях до папки з зображеннями\ntransform = transforms.Compose([\n    transforms.Resize((600, 450), interpolation=transforms.InterpolationMode.BICUBIC),\n    # transforms.CenterCrop(224),  # Не потрібно, якщо не хочете обрізати зображення\n    transforms.ToTensor(),\n    # Якщо не потрібно нормалізувати, можете прибрати:\n    # transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)) \n])\n\ndataset = CustomDataset(image_folder, transform)\ndataloader = DataLoader(dataset, batch_size=wandb.config.batch_size, shuffle=True)\n\n# # Створення та тренування автоенкодера\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nautoencoder = CNN_Autoencoder().to(device)\noptimizer = optim.Adam(autoencoder.parameters(), lr=wandb.config.learning_rate)\ncriterion = nn.MSELoss()  # Використовуємо BCE для бінарної класифікації\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=4, factor=0.1)\n\nfor epoch in range(wandb.config.epochs): \n    autoencoder.train()\n    train_loss = 0.0\n    \n    for data in dataloader:\n        data = data.to(device)\n        \n        optimizer.zero_grad()\n        output = autoencoder(data)\n        \n        # Враховуємо розмір для уникнення помилки розміру\n        data_resized = F.interpolate(data, size=(597, 453), mode='bicubic', align_corners=False)\n        \n        loss = criterion(output, data_resized)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    # Виведення тренувальних втрат\n    print(f\"Epoch [{epoch+1}/{wandb.config.epochs}], Loss: {train_loss/len(dataloader)}\")\n\n    # Оновлення швидкості навчання\n    scheduler.step(train_loss/len(dataloader))\n\n# Збереження моделі\ntorch.save(autoencoder.state_dict(), \"cnn_autoencoder.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T13:48:28.260231Z","iopub.execute_input":"2025-01-05T13:48:28.261039Z","iopub.status.idle":"2025-01-05T14:08:28.950115Z","shell.execute_reply.started":"2025-01-05T13:48:28.260975Z","shell.execute_reply":"2025-01-05T14:08:28.948331Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/40], Loss: 0.0036228455609817523\nEpoch [2/40], Loss: 0.0007202210491143774\nEpoch [3/40], Loss: 0.00042115589325296166\nEpoch [4/40], Loss: 0.00036933383727356933\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     23\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     26\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     28\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     13\u001b[0m     img_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_paths[idx]\n\u001b[0;32m---> 14\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     16\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:993\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    991\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m--> 993\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    995\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/ImageFile.py:300\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    299\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 300\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"# Отримання вихідного зображення після реконструкції\ntest_image = Image.open(\"/kaggle/input/dddddsd/photo_2025-01-05_14-25-25.jpg\").convert('RGB')\ntest_image = transform(test_image).unsqueeze(0).to(device)\noutput_image = autoencoder(test_image).detach().cpu().numpy()\n\n# Обчислення коефіцієнту кореляції\ntest_image_resized = transforms.functional.resize(test_image, (597, 453), interpolation=transforms.InterpolationMode.BICUBIC)\ninput_pixels = test_image_resized.squeeze(0).cpu().numpy().flatten()\n\nreconstructed_pixels = output_image.flatten()\ncorr_value = correlation_coefficient(input_pixels, reconstructed_pixels)\nprint(f\"Correlation Coefficient: {corr_value}\")\n\n# Масив кореляцій для класу (приклад)\ncorrelation_coeffs = np.random.rand(100)  # Масив кореляцій для класу\n\n# Обчислення порогу для цього класу\nthreshold = calculate_threshold(correlation_coeffs)\nprint(f\"Threshold: {threshold}\")\n\n# Перевірка чи зображення належить тому ж класу\nif corr_value > threshold:\n    print(\"Зображення належить тому ж класу.\")\nelse:\n    print(\"Зображення не належить тому ж класу.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T12:28:09.680192Z","iopub.execute_input":"2025-01-05T12:28:09.680576Z","iopub.status.idle":"2025-01-05T12:28:09.735982Z","shell.execute_reply.started":"2025-01-05T12:28:09.680510Z","shell.execute_reply":"2025-01-05T12:28:09.735111Z"}},"outputs":[{"name":"stdout","text":"Correlation Coefficient: 0.8697779178619385\nThreshold: 0.35221836510738785\nЗображення належить тому ж класу.\n","output_type":"stream"}],"execution_count":58}]}